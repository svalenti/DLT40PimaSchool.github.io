{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is intended to generate color images by stacking multi-band images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import sep\n",
    "import numpy as np\n",
    "from astropy.wcs import WCS\n",
    "import astropy.io.fits as pyfits\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.ndimage import interpolation as interp\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline:\n",
    "\n",
    "At the beginning of the class we tried to observe some Messier objects with a robotic telescope. Now we're going to put those data together to make a color image, or what astronomers often call an RGB image. Astronomical imaging is usually performed in specific filters which only allow certain wavelengths of light to pass through them. If you observe an object in 3 different filters, then each image you get will be a greyscale image, but you can assign each image a primary color (red/green/blue) and combine them to make a color image. Which is what we're going to do today."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What filters did we observe with?\n",
    "\n",
    "First we need to figure out what filters we observed with and which to assign to which primary color.\n",
    "\n",
    "We can quickly find this out by opening each fits file (FITS is the image format typically used in astronomy) and extracting the filter information from the file header.\n",
    "\n",
    "In this example we're going to be using images of M83 that were taken in 2021 (hopefully you have already downloaded these)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('M83*fits')\n",
    "filters = []\n",
    "for file in files:\n",
    "    #get the filter from the header\n",
    "    _filter = pyfits.getheader(file)['FILTER']\n",
    "    filters.append(_filter)\n",
    "filters = np.array(filters)\n",
    "files = np.array(files)\n",
    "print ('All the filters we have: ', np.unique(filters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question:\n",
    "\n",
    "<font color=blue>\n",
    "Which filter should we assign to Red, Green, and Blue?\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign each image to a filter name\n",
    "\n",
    "It is possible, and is often planned, that there are multiple images (or exposures) in a single filter. We don't want to throw away any good data, so we can average together exposures in the same filter, which will reduce the amount of random noise in the image.\n",
    "\n",
    "The first step in doing this is to collect together all the images and assign each a filter name. This kind of assignment is a good match for a python dictionary. In this case with only a small number of images you could write this dictionary manually, but if you had 100 or 1000 images that becomes much more inefficient. So we're going to using python to do this for us.\n",
    "\n",
    "## Exercise!\n",
    "\n",
    "<font color=blue>\n",
    "    Create a Dictionary called: <b>info</b><br>\n",
    "    Where:\n",
    "    <ul>\n",
    "        <li>keys = filter names (strings)</li>\n",
    "        <li>values = a list [] of file names for the images observed with that filter</li>\n",
    "    </ul>\n",
    "</font>\n",
    "\n",
    "#### Hints\n",
    " * a dictionary is instantiated as: `info = {'B':[], 'R':[], 'V':[]}`\n",
    " * create a loop over the files (like above) and `info[filter].append()` those files to their correct filter dictionary element "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We will use this dictionary to combine any images taken in the same filter in a moment, but first we need to get an idea of what the data are like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the data from one filter\n",
    "\n",
    "Now let's do what we normally do and visualize data ...\n",
    "\n",
    "## Exercise\n",
    "<font color=blue>\n",
    "    <ul>\n",
    "        <li>Grab the filename of the B band entry's first image from our dictionary.</li>\n",
    "        <li>Plot a histogram of the pixel values from the entire image.</li>\n",
    "    </ul>\n",
    "</font>\n",
    "\n",
    "#### Hints\n",
    "\n",
    "* use the `pyfits.getdata(filename)` to get the image data\n",
    "* plot it using `plt.hist(data.flatten(), bins=nbins, range=(lower, higher))`\n",
    "    * you'll have to figure out nbins, lower, higher on your own ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now...\n",
    "\n",
    "Let's display this image as an example.\n",
    "\n",
    "## Question:\n",
    "\n",
    "<font color=blue>From the histogram above, what values would you use for `vmin` and `vmax`?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin, vmax =  ????, ????\n",
    "\n",
    "fig= plt.figure(figsize=(10,12))\n",
    "\n",
    "#grab the coordinate solution to plot the RA/DEC grid\n",
    "header = pyfits.getheader(info['B'][0])\n",
    "wcs = WCS(header)\n",
    "ax = plt.subplot(projection=wcs)\n",
    "\n",
    "#plot the image\n",
    "data = pyfits.getdata(info['B'][0])\n",
    "ax.imshow(data, origin='lower', cmap='gray', vmin=vmin, vmax=vmax)\n",
    "ax.grid(color='white', ls='solid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Stacking\n",
    "\n",
    "Now we're going to stack (combine) images that were taken in the same filter.\n",
    "\n",
    "### How to:\n",
    "\n",
    "* Loop over each filter\n",
    "    * create a temporary dataset full of zeroes at the size we need\n",
    "    * loop over each file in the respective filters file_list\n",
    "        * get the image data and add it to our temporary dataset\n",
    "    * average the coadded data by the number of files\n",
    "    * save our averaged data to a dictionary with filters as the key\n",
    "    \n",
    "Note: Here we will use a normal average (e.g. mean), but often using the median is better for astronomical images as this removes outliers more effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is the dictionary we want to return\n",
    "band_image = {}\n",
    "#the size of our image: e.g. 1024x1024\n",
    "image_size = np.shape(data)\n",
    "\n",
    "#loop over our filter:files dictionary\n",
    "for band in info.keys():\n",
    "    print('Stacking all images in filter: {}'.format(band))\n",
    "    #creating a temporary data array\n",
    "    _data = np.zeros(image_size)\n",
    "    \n",
    "    #loop over our files list\n",
    "    band_files = info[band]\n",
    "    for file in band_files:\n",
    "        #add up all of our data\n",
    "        _data += pyfits.getdata(file)\n",
    "    \n",
    "    averaged_data = _data/float(len(band_files))\n",
    "    band_image.update({band: averaged_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the stacked data\n",
    "\n",
    "Now let's plot the combined image from the B band (in the M83 example).\n",
    "\n",
    "We're going to use exactly the same plotting function as before, but now the input data are different.\n",
    "\n",
    "## Question:\n",
    "\n",
    "\n",
    "<font color=blue>We created the dictionary `band_image` which contains the combined images for each filter. How do we need to re-define `data` before passing it to the `imshow` function?</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig= plt.figure(figsize=(10,12))\n",
    "\n",
    "#grab the coordinate solution to plot the RA/DEC grid\n",
    "header = pyfits.getheader(info['B'][0])\n",
    "wcs = WCS(header)\n",
    "ax = plt.subplot(projection=wcs)\n",
    "\n",
    "#plot the image\n",
    "data = pyfits.getdata(info['B'][0])\n",
    "ax.imshow(data, origin='lower', cmap='gray', vmin=vmin, vmax=vmax)\n",
    "ax.grid(color='white', ls='solid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make an RGB image\n",
    "\n",
    "* How will we do this:\n",
    "    * our bands need to be ordered from red-blue\n",
    "    * we loop over these ordered bands\n",
    "        * append the data to our `simpleRGB` list after applying a scale factor \n",
    "        * the scale factor will be from 0-1, closer to 1 the brighter the image will be in that color\n",
    "        \n",
    "    * `ax.imshow(simpleRGB)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = ['R', 'V', 'B'] # This needs to be ordered as R/G/B\n",
    "\n",
    "scale_factor = np.array([1.0, 0.9, 1.0]) \n",
    "\n",
    "simpleRGB=np.zeros((image_size[0],image_size[1],3),dtype=float)\n",
    "\n",
    "for i in range(len(bands)):\n",
    "    data = band_image[bands[i]].copy()\n",
    "    min_value = np.percentile(data, 2) #2nd percentile to 98th percentile\n",
    "    max_value = np.percentile(data, 98)\n",
    "    \n",
    "    #Scale the data so that the range goes from 0 to 1 for each image\n",
    "    data = (data - min_value)/(max_value-min_value)\n",
    "    \n",
    "    #Place the data for the current filter in the appropriate part of simpleRGB\n",
    "    simpleRGB[:,:,i]=(data*scale_factor[i])**1\n",
    "\n",
    "fig= plt.figure(figsize=(10,12))\n",
    "ax = plt.subplot(projection=wcs)\n",
    "ax.grid(color='white', ls='solid')\n",
    "img = ax.imshow(simpleRGB, origin='lower', interpolation='nearest',vmin=-40, vmax=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hmmm....\n",
    "\n",
    "It looks good, but not that great. The image stacking doesn't appear to be the greatest\n",
    "\n",
    "## Question:\n",
    "\n",
    "<font color=blue>\n",
    "    <ul>\n",
    "        <li>What signs can you see that there's a problem?</li>\n",
    "        <li>What should be done about it?</li>\n",
    "    </ul>\n",
    "</font>\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aligning the images\n",
    "\n",
    "We need to align the images better to remove artifacts.\n",
    "\n",
    "### How can we do this:\n",
    "\n",
    "* set the first image in our list as a reference\n",
    "* use `sep` to find the objects in the reference image\n",
    "* before stacking and averaging our data. Loop over every object in the iterated image, and the reference objects\n",
    "    * find the average offset by calculating the distance between the ref_obj and the iterated obj\n",
    "    * use a `scipy.ndimage.interpolate.shift()` to shift our data based off the offset\n",
    "* stack and average our offset image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is a function that searches for a reference object\n",
    "#once it finds it, it returns the shift in the x and y directions\n",
    "\n",
    "def find_offset(ref_x, ref_y, _data):\n",
    "    #Get the objects in our current image\n",
    "    _data = _data.byteswap().newbyteorder()\n",
    "    _data_bkg = sep.Background(_data)\n",
    "    data_objs = sep.extract(_data, thresh=20.0, err=_data_bkg.globalrms, minarea=8)\n",
    "    \n",
    "    #loop over them and calculate their distances\n",
    "    for i,j in enumerate(data_objs['x']):\n",
    "        shift_x = ref_x - data_objs['x'][i]\n",
    "        shift_y = ref_y - data_objs['y'][i]\n",
    "        distance = np.sqrt((shift_x)**2+(shift_y)**2)\n",
    "        \n",
    "        # if the distance is less than this threshhold, its a match\n",
    "        # return the offset x,y\n",
    "        if distance < 10:\n",
    "            return shift_x, shift_y\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_band_image = {}\n",
    "\n",
    "simpleRGB=np.zeros((image_size[0],image_size[1],3),dtype=float)\n",
    "\n",
    "image_size = np.shape(data)\n",
    "#These commands get the reference image objects\n",
    "ref_file = info[list(info.keys())[0]][0]\n",
    "ref_img = pyfits.getdata(ref_file)\n",
    "ref_img = ref_img.byteswap().newbyteorder() # magic command\n",
    "ref_bkg = sep.Background(ref_img)\n",
    "ref_objects = sep.extract(ref_img, thresh=20.0, err=ref_bkg.globalrms, minarea=10)\n",
    "\n",
    "#loop over the bands: RGB\n",
    "for band in info.keys():\n",
    "    print('Stacking all images in filter: {}'.format(band))\n",
    "    _shift_data = np.zeros(image_size)\n",
    "    \n",
    "    #loop over the files associated with each band\n",
    "    for file in info[band]:\n",
    "        \n",
    "        #get the image data\n",
    "        tmp_data = pyfits.getdata(file)\n",
    "        \n",
    "        #our lists to hold the offsets\n",
    "        sx, sy = [], []\n",
    "        \n",
    "        #loop over each reference object\n",
    "        for i,j in enumerate(ref_objects['x']):\n",
    "            #find and append the offsets to our lists\n",
    "            tmp_sx, tmp_sy = find_offset(ref_objects['x'][i], ref_objects['y'][i], tmp_data)\n",
    "            sx.append(tmp_sx)\n",
    "            sy.append(tmp_sy)\n",
    "\n",
    "        #calculate the average offset\n",
    "        shift_x, shift_y = np.mean(sx), np.mean(sy)\n",
    "\n",
    "        print('Average offsets in x: {}, y: {}\\n'.format(round(shift_x, 3), round(shift_y, 3)))\n",
    "        \n",
    "        #scipy method that shifts the image based off these offsets\n",
    "        new_data = interp.shift(tmp_data, [shift_y, shift_x])\n",
    "        #new coadded data from the shift\n",
    "        _shift_data += new_data\n",
    "\n",
    "    shift_band_image.update({band: _shift_data/float(len(info[band]))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's plot our aligned/stacked data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = ['R', 'V', 'B'] # This needs to be ordered as R/G/B\n",
    "\n",
    "scale_factor = np.array([1.0, 0.9, 1.0]) \n",
    "\n",
    "simpleRGB=np.zeros((image_size[0],image_size[1],3),dtype=float)\n",
    "\n",
    "\n",
    "for i in range(len(bands)):\n",
    "    data = shift_band_image[bands[i]].copy()\n",
    "    min_value = np.quantile(data, [0.03, 1-0.03])[0]\n",
    "    max_value = np.quantile(data, [0.03, 1-0.03])[1]\n",
    "    data = (data - min_value)/(max_value-min_value)\n",
    "    simpleRGB[:,:,i]=(data*scale_factor[i])**1.\n",
    "\n",
    "fig= plt.figure(figsize=(10,12))\n",
    "ax = plt.subplot(projection=wcs)\n",
    "ax.grid(color='white', ls='solid')\n",
    "img = ax.imshow(simpleRGB, origin='lower', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mis-alignment is fixed! However, the image still looks pretty noisy and it's hard to clearly see the fainter regions of the galaxy. You can change the power the image is scaled by (`simpleRGB[:,:,i]=(data*scale_factor[i])**1.`), e.g. try 0.5 or 2, but this will only help so much. Setting the correct visual scale in astronomy is always a trade off. Making the fainter parts of the image stand out will result in the brightest parts being saturated. What scale you want to choose usually depends on what features you are most interested in e.g. the galactic nucleus of the edges of the spiral arms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smooth the image\n",
    "\n",
    "One simple way to enhance the image, reduce its noise, and bring out the faint features is to smooth (or blur) it. When smoothed random noise in adjacent pixels will tend to cancel out on average, but real emission coming from the galaxy won't cancel out. So the real emission will appear stronger against the background. The trade off is that the image will be more blurry. For some science cases it's vital to have high resolution images and smoothing is not really an option, but for investigations of diffuse, faint objects smoothing will likely be benefitial.\n",
    "\n",
    "To perform the smoothing we will use the `scipy` function `gaussian_filter`. You cell phone camera probably has a Gaussian filter function. The function smooths/blurs the image using a Guassian function (a bell shape) of width N pixels. Here we're going to use N=2, but you can experiment with different values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = ['R', 'V', 'B'] # This needs to be ordered as R/G/B\n",
    "scale_factor = np.array([1.0, 0.85, 1.0])\n",
    "size = 1024\n",
    "simpleRGB=np.zeros((size,size,3),dtype=float)\n",
    "\n",
    "N_smooth = 2\n",
    "\n",
    "\n",
    "for i in range(len(bands)):\n",
    "    data = shift_band_image[bands[i]].copy()\n",
    "    min_value = np.percentile(data, 2) #2nd percentile to 98th percentile\n",
    "    max_value = np.percentile(data, 98)\n",
    "    data = (data - min_value)/(max_value-min_value)\n",
    "    simpleRGB[:,:,i]=(data*scale_factor[i])**1.\n",
    "    \n",
    "    simpleRGB[:,:,i] = gaussian_filter(simpleRGB[:,:,i],N_smooth,mode='wrap')\n",
    "\n",
    "fig= plt.figure(figsize=(10,12))\n",
    "ax = plt.subplot(projection=wcs)\n",
    "ax.grid(color='white', ls='solid')\n",
    "img = ax.imshow(simpleRGB, origin='lower', interpolation='nearest')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, things are looking pretty good now. The image is aligned well, the smoothing reduced the noise and brought out the fainter features. However, there are black spots all over the image.\n",
    "\n",
    "## Question:\n",
    "\n",
    "<font color=blue>\n",
    "    <ul>\n",
    "        <li>What might be causing the black spots? </li>\n",
    "        <li>Why are they visible in this image, but not the previous one? </li>\n",
    "    </ul>\n",
    "</font>\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clip the image\n",
    "\n",
    "To remove the black spots we can clip the image (before smoothing) to eliminate the bad pixels. In general in science you need to be very careful about modifying your data and this might create a bias in your final results. However, in this case our goal is to make a beautiful final image, like a publisher would for a popular science article, so this approach is ok. For an image which we were going to do science with, we would need to be more careful and identify each bad pixel and mask it.\n",
    "\n",
    "To perform the clipping we will just take the `min_value` and `max_value` that we already defined and clip the data at these values using the `numpy` function `clip`, then smooth as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = ['R', 'V', 'B'] # This needs to be ordered as R/G/B\n",
    "scale_factor = np.array([1.0, 0.85, 1.0])\n",
    "size = 1024\n",
    "simpleRGB=np.zeros((size,size,3),dtype=float)\n",
    "\n",
    "\n",
    "for i in range(len(bands)):\n",
    "    data = shift_band_image[bands[i]].copy()\n",
    "    min_value = np.percentile(data, 2) #2nd percentile to 98th percentile\n",
    "    max_value = np.percentile(data, 98)\n",
    "    \n",
    "    #data = (data - min_value)/(max_value-min_value)\n",
    "    data = (np.clip(data,min_value,max_value) - min_value)/(max_value-min_value) #New line with clipping\n",
    "    \n",
    "    simpleRGB[:,:,i]=(data*scale_factor[i])**1.\n",
    "\n",
    "    simpleRGB[:,:,i] = gaussian_filter(simpleRGB[:,:,i],2.,mode='wrap')\n",
    "\n",
    "fig= plt.figure(figsize=(10,12))\n",
    "ax = plt.subplot(projection=wcs)\n",
    "ax.grid(color='white', ls='solid')\n",
    "img = ax.imshow(simpleRGB, origin='lower', interpolation='nearest')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perfect!\n",
    "\n",
    "Show your friends and family, let them know you know how to make the Astronomy pictures the same way the Hubble does!\n",
    "\n",
    "Save all of your notebooks and save them for future projects. Maybe you can try out creating a similar image for other objects observed with skynet.\n",
    "\n",
    "It's been a wonderful semester, and I hope you have a great summer : )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
