{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import glob,scipy\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import scipy.ndimage as snd\n",
    "from scipy import optimize\n",
    "#import seaborn as sb\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First grab a list of all filenames inside of the defined root directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rootdir='hutch_data_files/'\n",
    "all_fits_filenames=np.array(glob.glob(rootdir+'/*/*.fit'))\n",
    "folder_names=np.array([fooname.split('/')[-2] for fooname in all_fits_filenames])\n",
    "print(all_fits_filenames[:5],\"...\",all_fits_filenames[-5:])\n",
    "print(unique(folder_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, using the image headers read in from pyfits.getheader, sort the exposures into flats, biases, science frames, etc., as well as reading in the filter names and exposure times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_exp_types = np.array([fits.getheader(fooname)[\"IMAGETYP\"] for fooname in all_fits_filenames])\n",
    "print(\"Our exposure types\",unique(all_exp_types))\n",
    "\n",
    "bias_filenames = all_fits_filenames[np.where(all_exp_types=='Bias Frame')]\n",
    "print(\"Number of bias frames\",len(bias_filenames))\n",
    "\n",
    "dark_filenames = np.sort(all_fits_filenames[np.where(all_exp_types=='Dark Frame')])\n",
    "dark_exptimes=np.array([fits.getheader(fooname)[\"EXPTIME\"] for fooname in dark_filenames])\n",
    "print(\"Number of darks and exposure times\",str(len(dark_filenames)),unique(dark_exptimes))\n",
    "\n",
    "flat_filenames = all_fits_filenames[np.where(all_exp_types=='Flat Field')]\n",
    "flat_filter_names=np.array([fits.getheader(fooname)[\"FILTER\"] for fooname in flat_filenames])\n",
    "flat_exptimes=np.array([fits.getheader(fooname)[\"EXPTIME\"] for fooname in flat_filenames])\n",
    "print(\"Flat filters and exposure times\",unique(flat_filter_names),unique(flat_exptimes))\n",
    "\n",
    "object_folder_name='m101'\n",
    "object_filenames= all_fits_filenames[np.where((folder_names==object_folder_name))]\n",
    "\n",
    "object_filter_names=np.array([fits.getheader(fooname)[\"FILTER\"] for fooname in object_filenames])\n",
    "object_exptimes=np.array([fits.getheader(fooname)[\"EXPTIME\"] for fooname in object_filenames])\n",
    "print(\"Object filters exposed and exposure times\",unique(object_filter_names),unique(object_exptimes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's make a median bias, flat, and dark frame. Use the definition below to stack them up and take the median value for each pixel in the stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Warning, reading in hundreds of bias frames may slow/kill your computer!\n",
    "# Index the filename array if you want to use a subset.\n",
    "\n",
    "def median_combine(filelist):\n",
    "    allimgs=[]\n",
    "    for filename in filelist: allimgs.append(fits.getdata(filename))\n",
    "    allimgs=np.array(allimgs)\n",
    "    medianimg=np.median(allimgs,axis=0)\n",
    "    return medianimg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a median bias frame and save it to the \"calib\" directory\n",
    "\n",
    "caldir = rootdir+'calib/'\n",
    "\n",
    "median_bias = median_combine(bias_filenames)\n",
    "\n",
    "fits.writeto(caldir+'median_bias.fits', median_bias, clobber=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a median dark frame and save it to the \"calib\" directory\n",
    "\n",
    "# 60 second dark frames\n",
    "dark_60 = np.where(dark_exptimes==60)\n",
    "print(dark_filenames[dark_60])\n",
    "\n",
    "median_dark_60 = median_combine(dark_filenames[dark_60])\n",
    "\n",
    "fits.writeto(caldir+'median_dark_60s.fits', median_dark_60, clobber=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_filter_names,flat_exptimes[np.where(flat_filter_names=='H-a')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make median flat frames for each filter\n",
    "\n",
    "# B band\n",
    "thefilt = 'B'\n",
    "flat_time = 30\n",
    "flat_files = flat_filenames[np.where((flat_filter_names==thefilt) & (flat_exptimes==flat_time))]\n",
    "print(flat_files)\n",
    "\n",
    "median_flat=median_combine(flat_files)\n",
    "fits.writeto(caldir+'median_flat_'+thefilt+'.fits',median_flat,clobber=True)\n",
    "\n",
    "# V band\n",
    "thefilt = 'V'\n",
    "flat_time = 10\n",
    "flat_files = flat_filenames[np.where((flat_filter_names==thefilt) & (flat_exptimes==flat_time))]\n",
    "print(flat_files)\n",
    "\n",
    "median_flat=median_combine(flat_files)\n",
    "fits.writeto(caldir+'median_flat_'+thefilt+'.fits',median_flat,clobber=True)\n",
    "\n",
    "# R band\n",
    "thefilt = 'R'\n",
    "flat_time = 10\n",
    "flat_files = flat_filenames[np.where((flat_filter_names==thefilt) & (flat_exptimes==flat_time))]\n",
    "print(flat_files)\n",
    "\n",
    "median_flat=median_combine(flat_files)\n",
    "fits.writeto(caldir+'median_flat_'+thefilt+'.fits',median_flat,clobber=True)\n",
    "\n",
    "# I band\n",
    "thefilt = 'I'\n",
    "flat_time = 10\n",
    "flat_files = flat_filenames[np.where((flat_filter_names==thefilt) & (flat_exptimes==flat_time))]\n",
    "print(flat_files)\n",
    "\n",
    "median_flat=median_combine(flat_files)\n",
    "fits.writeto(caldir+'median_flat_'+thefilt+'.fits',median_flat,clobber=True)\n",
    "\n",
    "# [O III] band\n",
    "thefilt = 'O-III'\n",
    "flat_time = 60\n",
    "flat_files = flat_filenames[np.where((flat_filter_names==thefilt) & (flat_exptimes==flat_time))]\n",
    "print(flat_files)\n",
    "\n",
    "median_flat=median_combine(flat_files)\n",
    "fits.writeto(caldir+'median_flat_'+thefilt+'.fits',median_flat,clobber=True)\n",
    "\n",
    "# H-alpha band\n",
    "thefilt = 'H-a'\n",
    "flat_time = 60\n",
    "flat_files = flat_filenames[np.where((flat_filter_names==thefilt) & (flat_exptimes==flat_time))]\n",
    "print(flat_files)\n",
    "\n",
    "median_flat=median_combine(flat_files)\n",
    "fits.writeto(caldir+'median_flat_'+thefilt+'.fits',median_flat,clobber=True)\n",
    "\n",
    "# [S II] band\n",
    "thefilt = 'S-II'\n",
    "flat_time = 60\n",
    "flat_files = flat_filenames[np.where((flat_filter_names==thefilt) & (flat_exptimes==flat_time))]\n",
    "print(flat_files)\n",
    "\n",
    "median_flat=median_combine(flat_files)\n",
    "fits.writeto(caldir+'median_flat_'+thefilt+'.fits',median_flat,clobber=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the median flat, bias, and dark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(median_flat,vmax=np.median(median_flat)+3*np.std(median_flat),cmap=plt.cm.coolwarm)\n",
    "plt.title('Median flat - '+thefilt,fontsize=25)\n",
    "plt.colorbar()\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(median_bias,vmax=np.median(median_bias)+3*np.std(median_bias),cmap=plt.cm.RdBu_r)\n",
    "plt.title('Median bias frame',fontsize=25)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(median_dark_60,vmin=np.median(median_dark_60)-0.1*np.std(median_dark_60),vmax=np.median(median_dark_60)+0.1*np.std(median_dark_60),cmap=plt.cm.spring),colorbar()\n",
    "plt.title('Median dark frame',fontsize=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's reduce the science frames using standard intrument signature removal. Note we subtract the dark and bias from the science, and divide by a normalized flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reduce_raw_science_frames(science_filelist,bias_file,flat_file,flat_exptime,dark_file,dark_exptime):\n",
    "    # Read the bias, flat, and dark files\n",
    "    bias = fits.getdata(bias_file)\n",
    "    dark = fits.getdata(dark_file)\n",
    "    flat = fits.getdata(flat_file)\n",
    "    \n",
    "    # Normalize the flat field\n",
    "    flat_darkcorr = (dark-bias) * (flat_exptime/dark_exptime)\n",
    "    flat_corr = (flat-bias-flat_darkcorr)\n",
    "    normed_flat = flat_corr/np.median(flat_corr)\n",
    "    \n",
    "    # Reduce the science frames\n",
    "    allreducedimgs=[]\n",
    "    for filename in science_filelist: \n",
    "        science_frame   = fits.getdata(filename)\n",
    "        science_exptime = fits.getheader(filename)[\"EXPTIME\"]\n",
    "        dark_science    = (dark-bias) * (science_exptime/dark_exptime)\n",
    "        reduced_frame   = (science_frame-dark_science-bias)/normed_flat\n",
    "        allreducedimgs.append(reduced_frame)\n",
    "    allreducedimgs=np.array(allreducedimgs)\n",
    "    return allreducedimgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the raw science frames and reduce them using the above definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_filter_names,object_exptimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calibration filenames\n",
    "bias_file = caldir+'median_bias.fits'\n",
    "dark_file = caldir+'median_dark_60s.fits'\n",
    "dark_exptime = 60.\n",
    "\n",
    "# R band object images\n",
    "thefilt = 'R'\n",
    "flat_file = caldir+'median_flat_'+thefilt+'.fits'\n",
    "flat_exptime = 10.\n",
    "  # Object frames\n",
    "science_filenames=object_filenames[np.where(object_filter_names==thefilt)]\n",
    "print(science_filenames)\n",
    "  # Reduce all frames \n",
    "science_reduced = reduce_raw_science_frames(science_filenames,bias_file,flat_file,flat_exptime,dark_file,dark_exptime)\n",
    "print(science_filenames[0].replace('.fit','_'+thefilt+'_reduced.fits'))\n",
    "  # Save the reduced frames to a new FITS file\n",
    "for i in range(len(science_reduced)):\n",
    "    fits.writeto(science_filenames[i].replace('.fit','_'+thefilt+'_reduced.fits'),science_reduced[i],clobber=True,header=fits.getheader(science_filenames[i]))\n",
    "\n",
    "# H-alpha band object images\n",
    "thefilt = 'H-a'\n",
    "flat_file = caldir+'median_flat_'+thefilt+'.fits'\n",
    "flat_exptime = 60.\n",
    "  # Object frames\n",
    "science_filenames=object_filenames[np.where(object_filter_names==thefilt)]\n",
    "print(science_filenames)\n",
    "  # Reduce all frames \n",
    "science_reduced = reduce_raw_science_frames(science_filenames,bias_file,flat_file,flat_exptime,dark_file,dark_exptime)\n",
    "print(science_filenames[0].replace('.fit','_'+thefilt+'_reduced.fits'))\n",
    "  # Save the reduced frames to a new FITS file\n",
    "for i in range(len(science_reduced)):\n",
    "    fits.writeto(science_filenames[i].replace('.fit','_'+thefilt+'_reduced.fits'),science_reduced[i],clobber=True,header=fits.getheader(science_filenames[i]))\n",
    "\n",
    "# B band object images\n",
    "thefilt = 'B'\n",
    "flat_file = caldir+'median_flat_'+thefilt+'.fits'\n",
    "flat_exptime = 30.\n",
    "  # Object frames\n",
    "science_filenames=object_filenames[np.where(object_filter_names==thefilt)]\n",
    "print(science_filenames)\n",
    "  # Reduce all frames \n",
    "science_reduced = reduce_raw_science_frames(science_filenames,bias_file,flat_file,flat_exptime,dark_file,dark_exptime)\n",
    "print(science_filenames[0].replace('.fit','_'+thefilt+'_reduced.fits'))\n",
    "  # Save the reduced frames to a new FITS file\n",
    "for i in range(len(science_reduced)):\n",
    "    fits.writeto(science_filenames[i].replace('.fit','_'+thefilt+'_reduced.fits'),science_reduced[i],clobber=True,header=fits.getheader(science_filenames[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do the pixel values of the reduced frames look like? Note there is a sky level, which provides a noisy minimum to all of the reduced pixel values. Find it by taking a histogram of the pixel values and taking the pixel value which is at the maximum of the histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,9))\n",
    "skylevels=[]\n",
    "for i in range(len(science_reduced)):\n",
    "    numpix,aduvals=np.histogram(science_reduced[i].flatten(),bins=1000,range=[-1e3,5e3])\n",
    "    skylevel=aduvals[where(numpix==numpix.max())][0]\n",
    "    skylevels.append(skylevel)\n",
    "    plt.plot(aduvals[:-1],numpix,label=str(science_filenames[i].split('/')[-1]))\n",
    "    plt.axvline(skylevel,color='k')\n",
    "plt.xlabel('pix val',fontsize=20)\n",
    "plt.ylabel('number of pixels',fontsize=20)\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "print(skylevels)\n",
    "plt.title('Histogram of reduced '+thefilt+' frame pixel values',fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show an example of the difference between reduced and unreduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testnum=0  #the file number to show comparison plot\n",
    "print(science_filenames[testnum])\n",
    "nstd=0.3\n",
    "unreduced=fits.getdata(science_filenames[testnum])\n",
    "print(np.std(unreduced))\n",
    "figure(figsize=(20,8))\n",
    "plt.subplot(121)\n",
    "#vmin_unred=np.median(median_bias)+skylevels[testnum]\n",
    "vmin_unred=np.median(unreduced)\n",
    "print(vmin_unred)\n",
    "plt.imshow(unreduced,cmap=cm.Greys,vmin=vmin_unred,vmax=vmin_unred+nstd*np.std(unreduced))\n",
    "plt.colorbar()\n",
    "plt.subplot(122)\n",
    "plt.imshow(science_reduced[testnum],cmap=cm.Greys,vmin=skylevels[testnum],vmax=skylevels[testnum]+nstd*np.std(unreduced))\n",
    "plt.colorbar()\n",
    "plt.suptitle('The difference between reduced and unreduced',fontsize=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's find some objects in the field, using a simplified object & centroid finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_object_centroids_filterbysize(img,threshold,minsize):\n",
    "    labels, num = snd.label(img > threshold, np.ones((3,3)))     # scipy labels/segments the image using a threshold\n",
    "    centers = snd.center_of_mass(img, labels, range(1,num+1))    # scipy calculates the center of mass on the labeled img\n",
    "    x = array(centers)[:,1]\n",
    "    y = array(centers)[:,0]\n",
    "    slices=snd.find_objects(labels)\n",
    "    xs=np.array([objlabel[1].stop-objlabel[1].start for objlabel in slices])  # takes the min and max label slices\n",
    "    ys=np.array([objlabel[0].stop-objlabel[0].start for objlabel in slices])  #  to find a rough object size\n",
    "\n",
    "    maxsize=1025    # I hardcoded this in so that some spurious objects would be skipped. Change/delete if you like\n",
    "    bigenough=np.where((xs>minsize) & (ys>minsize) & (xs<maxsize) & (ys<maxsize))\n",
    "    xc,yc=x[bigenough],y[bigenough]\n",
    "    xs,ys=xs[bigenough],ys[bigenough]\n",
    "    \n",
    "    print(str(len(xc))+' objects found')\n",
    "    return xc,yc,xs,ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test out the object finder on a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgnum=0\n",
    "nstd_aboveskynoise=10\n",
    "threshold=skylevels[imgnum]+nstd_aboveskynoise*np.sqrt(skylevels[imgnum])   # decide on a threshold using the sky noise\n",
    "minsize=2\n",
    "\n",
    "xfoo,yfoo,xsfoo,ysfoo=find_object_centroids_filterbysize(science_reduced[imgnum],threshold,minsize)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(science_reduced[imgnum],cmap=cm.Greys,vmin=0,vmax=1.5*threshold)\n",
    "plt.plot(xfoo,yfoo,'rs',mfc='None',markersize=20,markeredgecolor='b',markeredgewidth=2)\n",
    "axis([0,1024,0,1024])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just a little definition which can grab postage stamps of objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stamp(img,starx,stary,ws):\n",
    "    xlo,xhi,ylo,yhi=int(starx-ws),int(starx+ws),int(stary-ws),int(stary+ws)\n",
    "    xmin,ymin=0,0\n",
    "    xmax,ymax=np.shape(img)\n",
    "    if xlo<xmin: xlo=xmin\n",
    "    if xhi>xmax: xhi=xmax\n",
    "    if ylo<ymin: ylo=ymin\n",
    "    if yhi>ymax: yhi=ymax\n",
    "    return img[ylo:yhi,xlo:xhi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(xfoo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objnum=11\n",
    "ws=30\n",
    "stamp=get_stamp(science_reduced[imgnum],xfoo[objnum],yfoo[objnum],ws)\n",
    "plt.imshow(stamp,interpolation='None',vmin=0,vmax=1.5*threshold)\n",
    "xcfoo,ycfoo=ws+xfoo[objnum]-floor(xfoo[objnum]),ws+yfoo[objnum]-floor(yfoo[objnum])\n",
    "plot(xcfoo,ycfoo,'wo')\n",
    "plt.colorbar()\n",
    "axis([0,ws*2,0,ws*2])\n",
    "plt.title('a sample stamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now find objects in all the reduced frames, again using the sky noise from each reduced image as a threshold. Plot all the centroids detected in each image to illustrate the dithering that occurs between frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nstd_aboveskynoise=10\n",
    "thresholds=skylevels+nstd_aboveskynoise*np.sqrt(skylevels)\n",
    "\n",
    "#thresholds=[threshold]*len(science_reduced)\n",
    "minsize=2\n",
    "catalog={'x':[],'y':[]}\n",
    "xc_all,yc_all,xs_all,ys_all=[],[],[],[]\n",
    "figure(figsize=(15,6))\n",
    "for i in range(len(science_reduced)):\n",
    "    xfoo,yfoo,xsfoo,ysfoo=find_object_centroids_filterbysize(science_reduced[i],thresholds[i],minsize)\n",
    "    xc_all.append(xfoo)\n",
    "    yc_all.append(yfoo)\n",
    "    xs_all.append(xsfoo)\n",
    "    ys_all.append(ysfoo)\n",
    "    subplot(121)\n",
    "    plot(xfoo,yfoo,'o')\n",
    "    subplot(122)\n",
    "    plot(xfoo,yfoo,'.')\n",
    "    axis([0,400,600,1000])\n",
    "subplot(121)\n",
    "title('all objects found in all frames')\n",
    "subplot(122)\n",
    "title('zoomed in to illustrate dithering')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's make a little definition to find all matching objects given two frame's object centroids. If objects are chosen carefully, this can give us a rough offset between the frames, as is shown in the histogram below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_closest(xc0,yc0,xc1,yc1,dr):\n",
    "    nobjs1=len(xc1)\n",
    "    x_off,y_off=[],[]\n",
    "    for i in range(nobjs1):\n",
    "        poss_match=np.where(np.sqrt((xc1[i]-xc0)**2+(yc1[i]-yc0)**2)<dr)[0]  # for each object in the second catalog, \n",
    "        x_off.extend([(xc1[i]-xc0[j]) for j in poss_match])                  #  find matches within a radius dr\n",
    "        y_off.extend([(yc1[i]-yc0[j]) for j in poss_match])\n",
    "    x_off=np.array(x_off)\n",
    "    y_off=np.array(y_off)\n",
    "    \n",
    "    n_xoff,xfoo=np.histogram(x_off,bins=dr*2,range=[-dr,dr])   # histogram all the offsets to find the maximum value\n",
    "    n_yoff,yfoo=np.histogram(y_off,bins=dr*2,range=[-dr,dr])   #  which corresponds to the rough offset between frames\n",
    "    x_peak=(xfoo[where(n_xoff==np.max(n_xoff))])[0]+(xfoo[1]-xfoo[0])/2.\n",
    "    y_peak=(yfoo[where(n_yoff==np.max(n_yoff))])[0]+(yfoo[1]-yfoo[0])/2.   # (note addition of half bin width)\n",
    "    return x_off,y_off,x_peak,y_peak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondnum=1   #change this to be the second frame you want to see the offsets for\n",
    "dr=60\n",
    "xc0,yc0,xc1,yc1=xc_all[0],yc_all[0],xc_all[secondnum],yc_all[secondnum]\n",
    "xoff,yoff,xpeak,ypeak=find_closest(xc0,yc0,xc1,yc1,dr)\n",
    " \n",
    "    \n",
    "hist(xoff,histtype='step',label='x offset',range=[-dr,dr],bins=dr,color='r')\n",
    "hist(yoff,histtype='step',label='y offset',range=[-dr,dr],bins=dr,color='b')\n",
    "\n",
    "axvline(xpeak,color='r')\n",
    "axvline(ypeak,color='b')\n",
    "\n",
    "xlabel('Nearest object centroid offset [pix]',fontsize=20)\n",
    "ylabel('Number of objects',fontsize=20)\n",
    "title('X/Y shift between frames',fontsize=25)\n",
    "\n",
    "figure(figsize=(10,10))\n",
    "plot(xc0,yc0,'g.')\n",
    "plot(xc1-xpeak,yc1-ypeak,'ro',mfc='None')\n",
    "\n",
    "#axis([100,400,100,400])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going a little further than the simple offsets above, iterate on this process to find the overall shifts down to subpixel accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_frame_shifts(x0,y0,x1,y1,dr0,nsteps):    #like the def above, take in two sets of coordinates\n",
    "    xshifts,yshifts=0,0\n",
    "    drs=[dr0,20,10,5,2.5,1.25]\n",
    "    for i in range(nsteps):\n",
    "        dr=dr0/(1.+i)      # slowly reduce the matching radius, to get rid of outliers\n",
    "        xoff,yoff,xpeak,ypeak=find_closest(x0,y0,x1-xshifts,y1-yshifts,dr)\n",
    "        #print xoff,yoff\n",
    "        n_xoff,xfoo=np.histogram(xoff,bins=50,range=[-dr,dr])\n",
    "        n_yoff,yfoo=np.histogram(yoff,bins=50,range=[-dr,dr])\n",
    "        #axvline(xpeak)\n",
    "        print(xpeak)\n",
    "        if i==0:\n",
    "            xshift,yshift=xpeak,ypeak    # the first rough offset estimate is the peak of the offset histogram\n",
    "        else:                            # successive offsets are found by taking the median value of the remainder\n",
    "            xshift,yshift=np.median(xoff[np.abs(xoff)<dr/2.]),np.median(yoff[np.abs(yoff)<dr/2.])\n",
    "        xshifts+=xshift        # add in each successive offset to the total\n",
    "        yshifts+=yshift\n",
    "        print(dr,xshifts,yshifts)\n",
    "        #plot(xshifts,yshifts,'o')\n",
    "    hist(xoff,histtype='step',color='r',bins=50)\n",
    "    hist(yoff,histtype='step',color='b',bins=50)\n",
    "    #plot(yfoo[1:],n_yoff,'b')\n",
    "    axvline(xshift,color='r')\n",
    "    axvline(yshift,color='b')\n",
    "    return xshifts,yshifts\n",
    "\n",
    "def find_closest(xc0,yc0,xc1,yc1,dr):\n",
    "    nobjs1=len(xc1)\n",
    "    x_off,y_off=[],[]\n",
    "    for i in range(nobjs1):\n",
    "        poss_match=np.where(np.sqrt((xc1[i]-xc0)**2+(yc1[i]-yc0)**2)<dr)[0]  # for each object in the second catalog, \n",
    "        x_off.extend([(xc1[i]-xc0[j]) for j in poss_match])                  #  find matches within a radius dr\n",
    "        y_off.extend([(yc1[i]-yc0[j]) for j in poss_match])\n",
    "    x_off=np.array(x_off)\n",
    "    y_off=np.array(y_off)\n",
    "    \n",
    "    n_xoff,xfoo=np.histogram(x_off,bins=int(dr*2),range=[-dr,dr])   # histogram all the offsets to find the maximum value\n",
    "    n_yoff,yfoo=np.histogram(y_off,bins=int(dr*2),range=[-dr,dr])   #  which corresponds to the rough offset between frames\n",
    "    x_peak=(xfoo[where(n_xoff==np.max(n_xoff))])[0]+(xfoo[1]-xfoo[0])/2.\n",
    "    y_peak=(yfoo[where(n_yoff==np.max(n_yoff))])[0]+(yfoo[1]-yfoo[0])/2.   # (note addition of half bin width)\n",
    "    return x_off,y_off,x_peak,y_peak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform this on the first and last images, to test the concept. The definition above also produces a histogram which can be used to ensure the algorithm is working properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstnum,secondnum=0,1   #two different numbers corresponding to different frames\n",
    "dr=60\n",
    "xc0,yc0,xc1,yc1=xc_all[firstnum],yc_all[firstnum],xc_all[secondnum],yc_all[secondnum]\n",
    "find_frame_shifts(xc0,yc0,xc1,yc1,dr,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now deploy the offset finder on all reduced images, relative to the first one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xshifts,yshifts=np.zeros(len(science_reduced)),np.zeros(len(science_reduced))\n",
    "for secondnum in range(1,len(science_reduced)):\n",
    "    xshifts[secondnum],yshifts[secondnum]=find_frame_shifts(xc_all[0],yc_all[0],xc_all[secondnum],yc_all[secondnum],dr,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xshifts,yshifts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use scipy's interpolation shifting algorithm to shift each reduced image by the negative of the offsets found above. This should match them all up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape(science_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nzoom=4\n",
    "resampled=np.zeros((len(science_reduced),1024*nzoom,1024*nzoom))\n",
    "for k in range(len(science_reduced)):\n",
    "    for i in range(1024):\n",
    "        for j in range(1024):\n",
    "            resampled[k,i*nzoom:(i+1)*nzoom,j*nzoom:(j+1)*nzoom]=science_reduced[k,i,j]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "science_shifted_resampled=np.array([snd.interpolation.shift(resampled[i],[-yshifts[i]*nzoom,-xshifts[i]*nzoom],order=3) for i in range(0,len(resampled))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fits.writeto(rootdir+thefilt+'-median-resampled.fits',np.median(science_shifted_resampled,axis=0),clobber='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "science_shifted_rescaled=np.array([snd.interpolation.shift(science_reduced[i],[-yshifts[i],-xshifts[i]],order=5)-skylevels[i] for i in range(0,len(science_reduced))])\n",
    "stackedimg=np.median(science_shifted_rescaled,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the median of the stacked image to ensure it worked okay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "figure(figsize=(14,12))\n",
    "title('Median stacked '+thefilt+' image',fontsize=10)\n",
    "imshow(stackedimg,cmap=cm.Greys,vmin=0,vmax=5*np.sqrt(median(skylevels)))\n",
    "colorbar()\n",
    "#plt.axis([200,700,200,700])\n",
    "fits.writeto(rootdir+thefilt+'-median.fits',stackedimg,clobber=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making an RGB image (aka align three images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rgbroot='hutch_data_files/m101/'\n",
    "rimg=fits.getdata(rgbroot+'00000179.M 101_R_reduced.fits')\n",
    "gimg=fits.getdata(rgbroot+'00000186.M 101_H-a_reduced.fits')\n",
    "bimg=fits.getdata(rgbroot+'00000180.M 101_B_reduced.fits')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nstd_r=20\n",
    "nstd_g=30\n",
    "nstd_b=12\n",
    "minsize=3\n",
    "skylevel_r,skylevel_g,skylevel_b=np.median(rimg[rimg>0]),np.median(gimg[gimg>0]),np.median(bimg[bimg>0])\n",
    "\n",
    "xr,yr,xsfoo,ysfoo=find_object_centroids_filterbysize(rimg,skylevel_r+nstd_r*np.sqrt(skylevel_r),minsize)\n",
    "xg,yg,xsfoo,ysfoo=find_object_centroids_filterbysize(gimg,skylevel_g+nstd_g*np.sqrt(skylevel_g),minsize)\n",
    "xb,yb,xsfoo,ysfoo=find_object_centroids_filterbysize(bimg,skylevel_b+nstd_b*np.sqrt(skylevel_b),minsize)\n",
    "\n",
    "\n",
    "plot(xr,yr,'ro',alpha=.4)\n",
    "plot(xg,yg,'go',alpha=.4)\n",
    "plot(xb,yb,'bo',alpha=.4)\n",
    "plt.figure()\n",
    "plot(xr,yr,'ro',alpha=.4)\n",
    "plot(xg,yg,'go',alpha=.4)\n",
    "plot(xb,yb,'bo',alpha=.4)\n",
    "plt.axis([0,400,700,1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr=30\n",
    "x_off_rb,y_off_rb=find_frame_shifts(xr,yr,xb,yb,dr,2)\n",
    "x_off_rg,y_off_rg=find_frame_shifts(xr,yr,xg,yg,dr,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(10,10))\n",
    "plot(xr,yr,'ro',alpha=.4)\n",
    "plot(xg-x_off_rg,yg-y_off_rg,'go',alpha=.4)\n",
    "plot(xb-x_off_rb,yb-y_off_rb,'bo',alpha=.4)\n",
    "#axis([500,700,200,400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbroot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_shifted=snd.interpolation.shift(gimg,[-y_off_rg,-x_off_rg],order=1)\n",
    "fits.writeto(rgbroot+'H-a-median-shifted.fits',g_shifted,clobber='True')\n",
    "\n",
    "b_shifted=snd.interpolation.shift(bimg,[-y_off_rb,-x_off_rb],order=1)\n",
    "fits.writeto(rgbroot+'B-median-shifted.fits',b_shifted,clobber='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scalesqrt(inputArray, scale_min=None, scale_max=None):\n",
    "    \"\"\"Performs sqrt scaling of the input numpy array.\"\"\"\n",
    "\n",
    "    imageData=numpy.array(inputArray, copy=True)\n",
    "\n",
    "    imageData = imageData.clip(min=scale_min, max=scale_max)\n",
    "    imageData = imageData - scale_min\n",
    "    indices = numpy.where(imageData < 0)\n",
    "    imageData[indices] = 0.0\n",
    "    imageData = numpy.sqrt(imageData)\n",
    "    imageData = imageData / math.sqrt(scale_max - scale_min)\n",
    "\n",
    "    return imageData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in three images for the r,g,b array. Each of these has been reduced, stacked, and shifted/rotated to be on a common coordinate system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbroot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rimg=fits.getdata(rgbroot+'00000179.M 101_R_reduced.fits')\n",
    "gimg=fits.getdata(rgbroot+'H-a-median-shifted.fits')\n",
    "bimg=fits.getdata(rgbroot+'B-median-shifted.fits')\n",
    "\n",
    "rgbstack=[rimg,gimg,bimg]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do a rescaling of the image data for the purposes of making the RGB image (which needs values between 0 and 8 bits (0-255). I use the sqrt scaling used in the definition above, with a min and max defined by 0 and some number of std deviations above the sky noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nstd=[15,5,10]   # number of standard deviations above sky noise to call an RGB pixel=255\n",
    "rgbimg=np.zeros((1024,1024,3))\n",
    "\n",
    "for i in range(3):\n",
    "    onecolor=rgbstack[i]\n",
    "    colorstd,colormed=np.std(onecolor[onecolor>10]),np.median(onecolor[onecolor>10])\n",
    "    scale_min,scale_max=colormed,colormed + nstd[i]*colorstd\n",
    "    rgbimg[:,:,i]=scalesqrt(onecolor, scale_min=scale_min, scale_max=scale_max)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, display our RGB image with imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(10,10))\n",
    "imshow(rgbimg,interpolation='None')\n",
    "#axis([150,800,50,800])\n",
    "axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
