{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a color image from images in three different bands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools from previous lectures\n",
    "* Loading FITS files.\n",
    "* Displaying/plotting FITS images.\n",
    "* Using Source Extractor to find positions of stars.\n",
    "* Finding separation between points in images.\n",
    "* Dictionaries, lists, strings, and loops.\n",
    "\n",
    "## New for this lecture\n",
    "* Use pixel value histogram to normalize image.\n",
    "* Combine three images to make an RGB color image.\n",
    "* Align different images of the same target.\n",
    "* Clip and smooth images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Most of these you've seen before\n",
    "import glob\n",
    "import sep\n",
    "import numpy as np\n",
    "from astropy.wcs import WCS\n",
    "import astropy.io.fits as pyfits\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Except maybe some scipy tools for basic image manipulation\n",
    "from scipy.ndimage import interpolation as interp\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline:\n",
    "\n",
    "At the beginning of the class we tried to observe some Messier objects with a robotic telescope. Now we're going to put those data together to make a color image, or what astronomers often call an RGB image. Astronomical imaging is usually performed in specific filters which only allow certain wavelengths of light to pass through them. If you observe an object in 3 different filters, then each image you get will be a greyscale image, but you can assign each image a primary color (red/green/blue) and combine them to make a color image. Which is what we're going to do today."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What filters did we observe with?\n",
    "\n",
    "First we need to figure out what filters we observed with and which to assign to which primary color.\n",
    "\n",
    "We can find this out by opening each fits file (FITS is the image format typically used in astronomy) and extracting the filter information from the file header.\n",
    "\n",
    "In this example we're going to be using images of M83 that were taken in 2021 (hopefully you have already downloaded these)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find all files in the current directory starting with \"M83\" and ending \"fits\"\n",
    "files = glob.glob('M83*fits')\n",
    "\n",
    "#Make an empty list to record filter names\n",
    "filters = []\n",
    "\n",
    "#Make an empty dictionary to record image filenames corresponding to each filter\n",
    "imgname_filters = {}\n",
    "\n",
    "#Loop over all the files that we found above\n",
    "for file in files:\n",
    "    #get the filter from the header\n",
    "    _filter = pyfits.getheader(file)['FILTER']\n",
    "    filters.append(_filter)\n",
    "    \n",
    "    #Make a new dictionary key for the filter name\n",
    "    #and assign the filename to that filter\n",
    "    imgname_filters[_filter] = file\n",
    "    \n",
    "print('All the filters we have: ', np.unique(filters))\n",
    "print(imgname_filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question:\n",
    "\n",
    "<font color=blue>\n",
    "Which filter should we assign to Red, Green, and Blue?\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint**: Maybe this plot of filter transmission curves will help. (Ignore the colors used to plot the curves.)\n",
    "\n",
    "![](http://spiff.rit.edu/classes/phys440/lectures/filters/bessell.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the data from one filter\n",
    "\n",
    "Now let's display one of the images. We're going to start by taking all the pixel values in an image and making a histogram of all the values. This will give us an idea of the minimum and maximum values that we want to set when we display the image.\n",
    "\n",
    "## Exercise\n",
    "<font color=blue>\n",
    "    <ul>\n",
    "        <li>Grab the filename of the B band entry's first image from our dictionary.</li>\n",
    "        <li>Plot a histogram of the pixel values from the entire image.</li>\n",
    "    </ul>\n",
    "</font>\n",
    "\n",
    "#### Hints\n",
    "\n",
    "* use the `pyfits.getdata(filename)` to get the image data\n",
    "* plot it using `plt.hist(data.flatten(), bins=nbins, range=(lower, higher))`\n",
    "    * you'll have to figure out what to use for nbins, lower, higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now...\n",
    "\n",
    "Let's display this image as an example.\n",
    "\n",
    "## Question:\n",
    "\n",
    "<font color=blue>From the histogram above, what values would you use for `vmin` and `vmax`?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin, vmax =  ????, ????\n",
    "\n",
    "fig = plt.figure(figsize=(10,12))\n",
    "\n",
    "#plot the image\n",
    "data = pyfits.getdata(imgname_filters['B'])\n",
    "plt.imshow(data, origin='lower', cmap='gray', vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make an RGB image\n",
    "\n",
    "* How will we do this:\n",
    "    * our bands need to be ordered from red-blue\n",
    "    * we loop over these ordered bands\n",
    "        * append the data to our `simpleRGB` list after applying a scale factor \n",
    "        * the scale factor will be from 0-1, closer to 1 the brighter the image will be in that color\n",
    "        \n",
    "    * `ax.imshow(simpleRGB)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This needs to be ordered as R/G/B\n",
    "bands = ['R', 'V', 'B'] \n",
    "\n",
    "#This will scale how bright images are in each filter\n",
    "scale_factor = np.array([1.0, 0.9, 1.0])\n",
    "\n",
    "#Use numpy to find size of image\n",
    "image_size = np.shape(data)\n",
    "\n",
    "#Make an empty set of three images\n",
    "RGBimage=np.zeros((image_size[0],image_size[1],3),dtype=float) \n",
    "\n",
    "#Loop over all the bands\n",
    "for i in range(len(bands)):\n",
    "    #Use the dictionary \"imgname_filters\" to read the image file in each band\n",
    "    data = pyfits.getdata(imgname_filters[bands[i]])\n",
    "    \n",
    "    #Set the minimum and maximum of the image\n",
    "    #using percentiles of the pixel values\n",
    "    min_value = np.percentile(data.flatten(), 2) #2nd percentile to 98th percentile\n",
    "    max_value = np.percentile(data.flatten(), 98)\n",
    "    \n",
    "    #Scale the data so that the range goes from 0 to 1 for each image\n",
    "    data = (data - min_value)/(max_value-min_value)\n",
    "    \n",
    "    #Place the data for the current filter in the appropriate part of simpleRGB\n",
    "    RGBimage[:,:,i] = data*scale_factor[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can display the stack of three images as a color image. Matplotlib knows that if you give it a stack of three images then it is probably meant to be a RGB image and it will display it as such automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,12))\n",
    "\n",
    "plt.imshow(RGBimage, origin='lower', interpolation='nearest',vmin=-40, vmax=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hmmm....\n",
    "\n",
    "It looks good, but not that great. The image stacking doesn't appear to be perfect.\n",
    "\n",
    "## Question:\n",
    "\n",
    "<font color=blue>\n",
    "    <ul>\n",
    "        <li>What signs can you see that there's a problem?</li>\n",
    "        <li>What should be done about it?</li>\n",
    "    </ul>\n",
    "</font>\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aligning the images\n",
    "\n",
    "We need to align the images better to remove artifacts.\n",
    "\n",
    "### How can we do this:\n",
    "\n",
    "* set the first image in our list as a reference\n",
    "* use `sep` to find the objects in the reference image\n",
    "* before stacking and averaging our data. Loop over every object in the iterated image, and the reference objects\n",
    "    * find the average offset by calculating the distance between the ref_obj and the iterated obj\n",
    "    * use a `scipy.ndimage.interpolate.shift()` to shift our data based off the offset\n",
    "* stack and average our offset image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is a function that searches for a reference object\n",
    "#once it finds it, it returns the shift in the x and y directions\n",
    "\n",
    "def find_offset(ref_x, ref_y, _data):\n",
    "    #Get the objects in our current image\n",
    "    _data = _data.byteswap().newbyteorder()\n",
    "    _data_bkg = sep.Background(_data)\n",
    "    data_objs = sep.extract(_data, thresh=20.0, err=_data_bkg.globalrms, minarea=8)\n",
    "    \n",
    "    #loop over them and calculate their distances\n",
    "    for i,j in enumerate(data_objs['x']):\n",
    "        shift_x = ref_x - data_objs['x'][i]\n",
    "        shift_y = ref_y - data_objs['y'][i]\n",
    "        distance = np.sqrt((shift_x)**2+(shift_y)**2)\n",
    "        \n",
    "        # if the distance is less than this threshhold, its a match\n",
    "        # return the offset x,y\n",
    "        if distance < 10:\n",
    "            return shift_x, shift_y\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_band_image = {}\n",
    "\n",
    "image_size = np.shape(data)\n",
    "#These commands get the reference image objects\n",
    "ref_file = imgname_filters['B']\n",
    "ref_img = pyfits.getdata(ref_file)\n",
    "ref_img = ref_img.byteswap().newbyteorder() # magic command\n",
    "ref_bkg = sep.Background(ref_img)\n",
    "ref_objects = sep.extract(ref_img, thresh=20.0, err=ref_bkg.globalrms, minarea=10)\n",
    "\n",
    "#loop over the bands: RGB\n",
    "for band in filters:\n",
    "    print('Stacking all images in filter: {}'.format(band))\n",
    "    _shift_data = np.zeros(image_size)\n",
    "    \n",
    "    #get the image data\n",
    "    tmp_data = pyfits.getdata(imgname_filters[band])\n",
    "\n",
    "    #our lists to hold the offsets\n",
    "    sx, sy = [], []\n",
    "\n",
    "    #loop over each reference object\n",
    "    for i,j in enumerate(ref_objects['x']):\n",
    "        #find and append the offsets to our lists\n",
    "        tmp_sx, tmp_sy = find_offset(ref_objects['x'][i], ref_objects['y'][i], tmp_data)\n",
    "        sx.append(tmp_sx)\n",
    "        sy.append(tmp_sy)\n",
    "\n",
    "    #calculate the average offset\n",
    "    shift_x, shift_y = np.mean(sx), np.mean(sy)\n",
    "\n",
    "    print('Average offsets in x: {}, y: {}\\n'.format(round(shift_x, 3), round(shift_y, 3)))\n",
    "\n",
    "    #scipy method that shifts the image based off these offsets\n",
    "    new_data = interp.shift(tmp_data, [shift_y, shift_x])\n",
    "    #new coadded data from the shift\n",
    "    _shift_data += new_data\n",
    "\n",
    "    shift_band_image.update({band: _shift_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's plot our aligned/stacked data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = ['R', 'V', 'B'] # This needs to be ordered as R/G/B\n",
    "\n",
    "scale_factor = np.array([1.0, 0.9, 1.0]) \n",
    "\n",
    "RGBimage = np.zeros((image_size[0],image_size[1],3),dtype=float)\n",
    "\n",
    "\n",
    "for i in range(len(bands)):\n",
    "    data = shift_band_image[bands[i]].copy()\n",
    "    \n",
    "    min_value = np.percentile(data.flatten(), 2) #2nd percentile to 98th percentile\n",
    "    max_value = np.percentile(data.flatten(), 98)\n",
    "    \n",
    "    data = (data - min_value)/(max_value-min_value)\n",
    "    RGBimage[:,:,i] = (data*scale_factor[i])**1.\n",
    "                      \n",
    "fig = plt.figure(figsize=(10,12))\n",
    "\n",
    "plt.imshow(RGBimage, origin='lower', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mis-alignment is fixed! \n",
    "\n",
    "However, the image still looks pretty noisy and it's hard to clearly see the fainter regions of the galaxy. You can change the power the image is scaled by (`RGBimage[:,:,i]=(data*scale_factor[i])**1.`), e.g. try 0.5 or 2, but this will only help so much. \n",
    "\n",
    "Setting the correct visual scale in astronomy is always a trade off. Making the fainter parts of the image stand out will result in the brightest parts being saturated. What scale you want to choose usually depends on what features you are most interested in e.g. the galactic nucleus of the edges of the spiral arms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smooth the image\n",
    "\n",
    "One simple way to enhance the image, reduce its noise, and bring out the faint features is to smooth (or blur) it. When an image is smoothed, random noise in adjacent pixels will tend to cancel out on average, but real emission coming from the galaxy won't cancel out. So the real emission will appear stronger against the background. The trade off is that the image will be more blurry. For some science cases it's vital to have high resolution images and smoothing is not really an option, but for investigations of diffuse, faint objects smoothing will likely be beneficial.\n",
    "\n",
    "To perform the smoothing we will use the `scipy` function `gaussian_filter`. Your cell phone camera probably has a Gaussian filter function to blur parts of images. The function smooths/blurs the image using a Guassian function (a bell shape) of width N pixels. Here we're going to use N=2, but you can experiment with different values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = ['R', 'V', 'B'] # This needs to be ordered as R/G/B\n",
    "scale_factor = np.array([1.0, 0.9, 1.0])\n",
    "RGBimage = np.zeros((image_size[0],image_size[1],3),dtype=float)\n",
    "\n",
    "N_smooth = 2\n",
    "\n",
    "\n",
    "for i in range(len(bands)):\n",
    "    data = shift_band_image[bands[i]].copy()\n",
    "    \n",
    "    min_value = np.percentile(data, 2) #2nd percentile to 98th percentile\n",
    "    max_value = np.percentile(data, 98)\n",
    "    \n",
    "    data = (data - min_value)/(max_value-min_value)\n",
    "    RGBimage[:,:,i] = (data*scale_factor[i])**1.\n",
    "    \n",
    "    RGBimage[:,:,i] = gaussian_filter(RGBimage[:,:,i],N_smooth,mode='wrap')\n",
    "\n",
    "fig= plt.figure(figsize=(10,12))\n",
    "\n",
    "plt.imshow(RGBimage, origin='lower', interpolation='nearest')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, things are looking pretty good now. \n",
    "\n",
    "The image is aligned well, the smoothing reduced the noise and brought out the fainter features. However, there are black spots all over the image.\n",
    "\n",
    "\n",
    "\n",
    "## Question:\n",
    "\n",
    "<font color=blue>\n",
    "    <ul>\n",
    "        <li>What might be causing the black spots? </li>\n",
    "        <li>Why are they visible in this image, but not the previous one? </li>\n",
    "    </ul>\n",
    "</font>\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clip the image\n",
    "\n",
    "To remove the black spots we can clip the image (before smoothing) to eliminate the bad pixels. In general in science you need to be very careful about manually modifying your data as this might create a bias in your final results. However, in this case our goal is to make a beautiful final image, like a publisher would for a popular science article, so this approach is ok. For an image which we were going to do science with, we would need to be more careful and identify each bad pixel and remove them individually.\n",
    "\n",
    "To perform the clipping we will just take the `min_value` and `max_value` that we already defined and clip the data at these values using the `numpy` function `clip`, then smooth as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = ['R', 'V', 'B'] # This needs to be ordered as R/G/B\n",
    "scale_factor = np.array([1.0, 0.9, 1.0])\n",
    "RGBimage = np.zeros((image_size[0],image_size[1],3),dtype=float)\n",
    "\n",
    "for i in range(len(bands)):\n",
    "    data = shift_band_image[bands[i]].copy()\n",
    "    \n",
    "    min_value = np.percentile(data, 2) #2nd percentile to 98th percentile\n",
    "    max_value = np.percentile(data, 98)\n",
    "    \n",
    "    #Added one line to clip the data\n",
    "    data = np.clip(data,min_value,max_value)\n",
    "    data = (data - min_value)/(max_value-min_value)\n",
    "    \n",
    "    RGBimage[:,:,i] = (data*scale_factor[i])**1.\n",
    "\n",
    "    RGBimage[:,:,i] = gaussian_filter(RGBimage[:,:,i],2.,mode='wrap')\n",
    "\n",
    "fig= plt.figure(figsize=(10,12))\n",
    "\n",
    "plt.imshow(RGBimage, origin='lower', interpolation='nearest')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perfect!\n",
    "\n",
    "Show your friends and family! You now know how to make the Astronomy pictures the same way the Hubble does!\n",
    "\n",
    "Save all of your notebooks and use them for future projects. Maybe you can try out creating a similar image for other objects observed with skynet.\n",
    "\n",
    "I hope you have a great summer : )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
